{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Binary classification using `pytket-qujax`"]},{"cell_type":"markdown","metadata":{},"source":["See the docs for [qujax](https://cqcl.github.io/qujax/) and [pytket-qujax](https://cqcl.github.io/pytket-qujax/api/index.html)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from jax import numpy as jnp, random, vmap, value_and_grad, jit\n","from pytket import Circuit\n","from pytket.circuit.display import render_circuit_jupyter\n","from pytket.extensions.qujax.qujax_convert import tk_to_qujax\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["# Define the classification task\n","We'll try and learn a _donut_ binary classification function (i.e. a bivariate coordinate is labelled 1 if it is inside the donut and 0 if it is outside)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inner_rad = 0.25\n","outer_rad = 0.75"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def classification_function(x, y):\n","    r = jnp.sqrt(x**2 + y**2)\n","    return jnp.where((r > inner_rad) * (r < outer_rad), 1, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["linsp = jnp.linspace(-1, 1, 1000)\n","Z = vmap(lambda x: vmap(lambda y: classification_function(x, y))(linsp))(linsp)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.contourf(linsp, linsp, Z, cmap=\"Purples\")"]},{"cell_type":"markdown","metadata":{},"source":["Now let's generate some data for our quantum circuit to learn from"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_data = 1000\n","x = random.uniform(random.PRNGKey(0), shape=(n_data, 2), minval=-1, maxval=1)\n","y = classification_function(x[:, 0], x[:, 1])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.scatter(x[:, 0], x[:, 1], alpha=jnp.where(y, 1, 0.2), s=10)"]},{"cell_type":"markdown","metadata":{},"source":["# Quantum circuit time\n","We'll use a variant of data re-uploading [Pérez-Salinas et al](https://doi.org/10.22331/q-2020-02-06-226) to encode the input data, alongside some variational parameters within a quantum circuit classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_qubits = 3\n","depth = 5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["c = Circuit(n_qubits)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for layer in range(depth):\n","    for qi in range(n_qubits):\n","        c.Rz(0.0, qi)\n","        c.Ry(0.0, qi)\n","        c.Rz(0.0, qi)\n","    if layer < (depth - 1):\n","        for qi in range(layer, layer + n_qubits - 1, 2):\n","            c.CZ(qi % n_qubits, (qi + 1) % n_qubits)\n","        c.add_barrier(range(n_qubits))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["render_circuit_jupyter(c)"]},{"cell_type":"markdown","metadata":{},"source":["We can use `pytket-qujax` to generate our angles-to-statetensor function."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["angles_to_st = tk_to_qujax(c)"]},{"cell_type":"markdown","metadata":{},"source":["We'll parameterise each angle as\n","\n","$$\n","\\begin{equation}\n","\\theta_k = b_k + w_k \\, x_k\n","\\end{equation}\n","$$\n","\n","where $b_k, w_k$ are variational parameters to be learnt and $x_k = x_0$ if $k$ even, $x_k = x_1$ if $k$ odd for a single bivariate input point $(x_0, x_1)$."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_angles = 3 * n_qubits * depth\n","n_params = 2 * n_angles"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def param_and_x_to_angles(param, x_single):\n","    biases = param[:n_angles]\n","    weights = param[n_angles:]\n","    weights_times_data = jnp.where(\n","        jnp.arange(n_angles) % 2 == 0, weights * x_single[0], weights * x_single[1]\n","    )\n","    angles = biases + weights_times_data\n","    return angles"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["param_and_x_to_st = lambda param, x_single: angles_to_st(\n","    param_and_x_to_angles(param, x_single)\n",")"]},{"cell_type":"markdown","metadata":{},"source":["We'll measure the first qubit only (if its 1 we label _donut_, if its 0 we label _not donut_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def param_and_x_to_probability(param, x_single):\n","    st = param_and_x_to_st(param, x_single)\n","    all_probs = jnp.square(jnp.abs(st))\n","    first_qubit_probs = jnp.sum(all_probs, axis=range(1, n_qubits))\n","    return first_qubit_probs[1]"]},{"cell_type":"markdown","metadata":{},"source":["For binary classification, the likelihood for our full data set $(x_{1:N}, y_{1:N})$ is\n","\n","$$\n","\\begin{equation}\n","p(y_{1:N} \\mid b, w, x_{1:N}) = \\prod_{i=1}^N p(y_i \\mid b, w, x_i) = \\prod_{i=1}^N (1 - q_{(b,w)}(x_i))^{I[y_i = 0]}q_{(b,w)}(x_i)^{I[y_i = 1]},\n","\\end{equation}\n","$$\n","\n","where $q_{(b, w)}(x)$ is the probability the quantum circuit classifies input $x$ as donut given variational parameter vectors $(b, w)$. This gives log-likelihood\n","\n","$$\n","\\begin{equation}\n"," \\log p(y_{1:N} \\mid b, w, x_{1:N}) = \\sum_{i=1}^N I[y_i = 0] \\log(1 - q_{(b,w)}(x_i)) + I[y_i = 1] \\log q_{(b,w)}(x_i),\n","\\end{equation}\n","$$\n","\n","which we would like to maximise.\n","\n","Unfortunately, the log-likelihood **cannot** be approximated unbiasedly using shots, that is we can approximate $q_{(b,w)}(x_i)$ unbiasedly but not $\\log(q_{(b,w)}(x_i))$.\n","Note that in qujax simulations we can use the statetensor to calculate this exactly, but it is still good to keep in mind loss functions that can also be used with shots from a quantum device.\n","\n","Instead we can minimise an expected distance between shots and data\n","\n","$$\n","\\begin{equation}\n","C(b, w, x, y) = E_{p(y' \\mid q_{(b, w)}(x))}[\\ell(y', y)] = (1 - q_{(b, w)}(x)) \\ell(0, y) +  q_{(b, w)}(x)\\ell(1, y),\n","\\end{equation}\n","$$\n","\n","where $y'$ is a shot, $y$ is a data label and $\\ell$ is some distance between bitstrings - here we simply set $\\ell(0, 0) = \\ell(1, 1) = 0$ and $\\ell(0, 1) = \\ell(1, 0) = 1$ (which coincides with the Hamming distance for this binary example).\n","\n"," The full batch cost function is\n","\n","$$\n","\\begin{equation}\n"," C(b, w) = \\frac1N \\sum_{i=1}^N C(b,\\, w,\\, x_i,\\, y_i).\n","\\end{equation}\n","$$"]},{"cell_type":"markdown","metadata":{},"source":["Note that to calculate the cost function we need to evaluate the statetensor for every input point $x_i$. If the dataset becomes too large, we can easily minibatch."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def param_to_cost(param):\n","    donut_probs = vmap(param_and_x_to_probability, in_axes=(None, 0))(param, x)\n","    costs = jnp.where(y, 1 - donut_probs, donut_probs)\n","    return costs.mean()"]},{"cell_type":"markdown","metadata":{},"source":["# Ready to descend some gradients?\n","We'll just use vanilla gradient descent here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["param_to_cost_and_grad = jit(value_and_grad(param_to_cost))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_iter = 1000\n","stepsize = 1e-1\n","param = random.uniform(random.PRNGKey(1), shape=(n_params,), minval=0, maxval=2)\n","costs = jnp.zeros(n_iter)\n","for i in range(n_iter):\n","    cost, grad = param_to_cost_and_grad(param)\n","    costs = costs.at[i].set(cost)\n","    param = param - stepsize * grad\n","    print(i, \"Cost: \", cost, end=\"\\r\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.plot(costs)\n","plt.xlabel(\"Iteration\")\n","plt.ylabel(\"Cost\")"]},{"cell_type":"markdown","metadata":{},"source":["# Visualise trained classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["linsp = jnp.linspace(-1, 1, 100)\n","Z = vmap(\n","    lambda a: vmap(lambda b: param_and_x_to_probability(param, jnp.array([a, b])))(\n","        linsp\n","    )\n",")(linsp)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.contourf(linsp, linsp, Z, cmap=\"Purples\", alpha=0.8)\n","circle_linsp = jnp.linspace(0, 2 * jnp.pi, 100)\n","plt.plot(inner_rad * jnp.cos(circle_linsp), inner_rad * jnp.sin(circle_linsp), c=\"red\")\n","plt.plot(outer_rad * jnp.cos(circle_linsp), outer_rad * jnp.sin(circle_linsp), c=\"red\")"]},{"cell_type":"markdown","metadata":{},"source":["Looks good, it has clearly grasped the donut shape. Sincerest apologies if you are now hungry! 🍩"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":2}
